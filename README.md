# Research-Grade Reasoning & Collapse Benchmarks  
**Author:** Rhishi Kumar Ayyappan  

---

## Portfolio Overview

A curated suite of cutting-edge projects exploring the boundaries of AI reasoning, reliability, and adaptive efficiency.  
Each folder delivers a research-backed, recruiter-ready demonstration of model limits—complete with visual benchmarks, advanced diagnostics, and business impact narratives.  
Perfect for recruiters, interviewers, research leads, and AI teams who care about explainability, risk, and efficient real-world deployment.  

---

## Projects

### 1. Chain-of-Thought Collapse Benchmark  
**Folder:** [Chain-of-Thought](https://github.com/rhishikumarayyappan/Research-Papers/tree/main/Chain-of-Thought)  
**Challenge:** How far can stepwise reasoning push model reliability?  
**Impact:** Instantly visualizes collapse points where AI fails on multi-step logic problems.  
**Highlights:**  
- Modular math problem generator  
- Automated collapse flagging  
- Easy-to-read charts and annotated trace outputs  
*See the project folder for code, charts, and recruiter commentary.*

---

### 2. DiffAdapt Difficulty-Adaptive Reasoning Simulator  
**Folder:** [DiffAdapt](https://github.com/rhishikumarayyappan/Research-Papers/tree/main/DiffAdapt)  
**Challenge:** Can models automatically "budget" how much reasoning to spend per question?  
**Impact:** Demonstrates adaptive inference strategies—saving tokens and compute, while diagnosing overthinking.  
**Highlights:**  
- Heuristic difficulty probe for free-tier models  
- Strategy selection: direct/stepwise/chain-of-thought  
- Side-by-side metrics for tokens, accuracy, and collapse  
*See project folder for business metrics, visuals, and documentation.*

---

### 3. The Illusion of Thinking - Limits of AI Explainability  
**Folder:** [The-Illusion-of-Thinking](https://github.com/rhishikumarayyappan/Research-Papers/tree/main/The-Illusion-of-Thinking)  
**Challenge:** Does more explanation mean more reliability in AI?  
**Impact:** Benchmarks how even detailed reasoning chains can mask model failure—empirically measuring collapse across complexities.  
**Highlights:**  
- Collapse tracking and instant replay  
- Business-ready visuals and risk flags  
- Connects findings to model selection, risk, and deployment  
*See folder for demos, charts, must-read summary cells.*

---

## Business Impact & Metrics

- All projects show **collapse points** and areas of unreliable reasoning, supporting risk management and robust engineering for stakeholders.
- Visualizations (charts, annotated badges, executive takeaways) make results instantly actionable.
- Metrics included for accuracy, token/compute use, and failure flags—benchmarking cost vs. reliability.
- Every project is modular and extensible, with portfolio-ready documentation.

---

## How to Use

- Browse each folder for README, code, generated outputs, and visual results.
- Follow install/run steps—instant demo in Colab or Jupyter.
- Use summary cells and business impact notes for interviews, team presentations, or technical assessment.

---

## Tech Highlights

- Python, pandas, numpy  
- matplotlib, seaborn  
- HuggingFace Transformers (free tier)
- Modular notebook design and ready-to-use requirements.txt

---

**Portfolio designed for clarity, research depth, and maximum business value.  
Contact for code review, demo requests, or real-world benchmarking collaboration!**
